# miika
The place to tell your worries.

To run inference.py in server, you need at least 6 GB of GPU RAM.